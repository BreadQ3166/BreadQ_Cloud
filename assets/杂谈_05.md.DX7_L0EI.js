import{_ as a,c as i,a3 as e,o as t}from"./chunks/framework.CI_7VurD.js";const p=JSON.parse('{"title":"前言","description":"","frontmatter":{"head":[["link",{"rel":"stylesheet","href":"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"}]]},"headers":[],"relativePath":"杂谈/05.md","filePath":"杂谈/05.md"}'),o={name:"杂谈/05.md"};function r(s,l,c,h,n,d){return t(),i("div",null,l[0]||(l[0]=[e('<h1 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言" aria-label="Permalink to &quot;前言&quot;">​</a></h1><blockquote><p>🍊Hello，各位好，我是面包！</p><p>这篇文档集合了面包的AI绘画生成基本标志物的经历。</p></blockquote><h3 id="🌭ai扩图-解决生成物品随机位置与大小" tabindex="-1">🌭AI扩图-解决生成物品随机位置与大小 <a class="header-anchor" href="#🌭ai扩图-解决生成物品随机位置与大小" aria-label="Permalink to &quot;🌭AI扩图-解决生成物品随机位置与大小&quot;">​</a></h3><ul><li>使用inpainting大模型【未进行】</li><li>编写自动化脚本进行大规模随机生成【未进行】</li><li>利用扩展画布【已成功】</li></ul><div class="tip custom-block"><p class="custom-block-title">小纸条</p><ol><li>生成与标志物有明显色差的纯色背景，比如（0,255,0）</li><li>通过扩展画布进行随机扩展</li><li>将图片缩放成最符合大模型训练集的尺寸接入工作流</li></ol></div><h3 id="🥕图像模糊-解决生成图像模糊度" tabindex="-1">🥕图像模糊-解决生成图像模糊度 <a class="header-anchor" href="#🥕图像模糊-解决生成图像模糊度" aria-label="Permalink to &quot;🥕图像模糊-解决生成图像模糊度&quot;">​</a></h3><ol><li>附加节点进行模糊处理【成功】</li></ol><div class="tip custom-block"><p class="custom-block-title">小纸条</p><p>利用高斯模糊直接进行模糊处理</p></div><h3 id="🥪不同光效" tabindex="-1">🥪不同光效 <a class="header-anchor" href="#🥪不同光效" aria-label="Permalink to &quot;🥪不同光效&quot;">​</a></h3><ul><li>在comfyui里使用ic-light节点【成功】</li></ul><div class="tip custom-block"><p class="custom-block-title">小纸条</p><ol><li>通过数学表达式节点随机生成圆形的遮罩，同时羽化边缘</li><li>调节应用ICLight节点连接的K采样器节点的降噪系数，系数越低，光照越接近光影遮罩</li></ol></div><div class="warning custom-block"><p class="custom-block-title">WARNING</p><ul><li>插件：【IC-Light】</li><li>节点工具：【加载ICLight模型】、【应用ICLight条件】</li><li>实现流程：通过模型与遮罩实现光影替换，并可以进一步添加图像细节</li></ul></div><h3 id="🍒随机数量" tabindex="-1">🍒随机数量 <a class="header-anchor" href="#🍒随机数量" aria-label="Permalink to &quot;🍒随机数量&quot;">​</a></h3><ul><li>通过遮罩复合节点生成生成【失败】</li><li>通过将正交(1<em>1，2</em>2，3<em>3,4</em>4)的图片组合，从有标志物与无标志物的图片中选取【成功】</li></ul><h3 id="🧀导出多个图像坐标" tabindex="-1">🧀导出多个图像坐标 <a class="header-anchor" href="#🧀导出多个图像坐标" aria-label="Permalink to &quot;🧀导出多个图像坐标&quot;">​</a></h3><ul><li>调用A=1的次数-&gt;图片中标志物的个数</li><li>将向左拓展作为x坐标，向上拓展作为y坐标，尺度缩放</li><li>将缩放后尺寸与缩放前尺寸作为缩放比例因子，进行比例降化</li></ul><div class="tip custom-block"><p class="custom-block-title">小纸条</p><ol><li>原缩放坐标/sqrt(输入照片数)</li><li>原缩放坐标/sqrt(输入照片数)，x轴+256</li><li>原缩放坐标/sqrt(输入照片数)，y轴+256</li><li>原缩放坐标/sqrt(输入照片数)，x轴+256，y轴+256</li></ol></div><h3 id="🥑雨幕添加" tabindex="-1">🥑雨幕添加 <a class="header-anchor" href="#🥑雨幕添加" aria-label="Permalink to &quot;🥑雨幕添加&quot;">​</a></h3><p>通过基础文生图工作流生成透明背景的雨幕图片，然后通过【图像混合模式】节点与高清放大后的图片通过【hard light模式】融合。</p><h3 id="🥘高清放大" tabindex="-1">🥘高清放大 <a class="header-anchor" href="#🥘高清放大" aria-label="Permalink to &quot;🥘高清放大&quot;">​</a></h3><p>通过分块采样与潜空间缩放生成与工业相机拍摄图片尺寸相符的图片</p><h3 id="🥮图片随机或有序读取" tabindex="-1">🥮图片随机或有序读取 <a class="header-anchor" href="#🥮图片随机或有序读取" aria-label="Permalink to &quot;🥮图片随机或有序读取&quot;">​</a></h3><ol><li>通过【图像批量处理】节点实现随机读取，可以实现单个标志物的图像生成</li><li>添加for循环实现随机选取并正交拼接，实现图片的单个或多个标志物随机选取，，但有可能只选到背景，没有标志物，特别是在一个标志物选择范围内，有二分之一的几率无标志物生成，浪费算力资源</li><li>添加switch节点，无法解决问题，switch与for循环节点之间 可能有调用冲突</li><li>将switch节点换成if节点，解决了生成一个标志物范围时大概率无标志物生成的问题，但生成多个标志物范围时还有小概率生成无标志物图片</li><li>利用for循环索引进行if判断，从而保证至少有一个标志物生成</li></ol><div class="warning custom-block"><p class="custom-block-title">前提</p><ul><li>插件：【was-node-suite-comfyui】</li><li>节点工具：【加载批次图像】</li><li>实现流程：设置模式为【single_image、incremental_image、random】-&gt; 设置绝对路径</li></ul></div><h3 id="🍝提示词随机生成" tabindex="-1">🍝提示词随机生成 <a class="header-anchor" href="#🍝提示词随机生成" aria-label="Permalink to &quot;🍝提示词随机生成&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">前提</p><ul><li>插件：【comfyui-dynamicprompts】</li><li>节点工具：【动态提示词】、【BrushNet加载器】</li><li>实现流程：通过模型处理可实现背景替换</li></ul></div><h3 id="🍛数据集的挑选" tabindex="-1">🍛数据集的挑选 <a class="header-anchor" href="#🍛数据集的挑选" aria-label="Permalink to &quot;🍛数据集的挑选&quot;">​</a></h3><p>1.将黑白圆盘放在桌子上，围绕标志物以45度和视角为变量拍摄 16张图片作为训练集</p><p>2.ps抠图制作 纯白背景</p><p>3.将sd1.5大模型修改成其他真实场景的大模型</p><h3 id="🍿背景" tabindex="-1">🍿背景 <a class="header-anchor" href="#🍿背景" aria-label="Permalink to &quot;🍿背景&quot;">​</a></h3><ol><li>通过扩图实现</li></ol><p>1.数据集收集，纯白背景，斜上方-8，正上方-8，</p><p>触发词，背景光影，视角</p><h3 id="🍺拍摄图片预处理" tabindex="-1">🍺拍摄图片预处理 <a class="header-anchor" href="#🍺拍摄图片预处理" aria-label="Permalink to &quot;🍺拍摄图片预处理&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">前提</p><ul><li>插件：【】</li><li>节点工具：【SAM模型加载器】、【G-Dino模型加载器】、【G-DinoSAM语义分割】</li><li>实现流程：通过模型处理后可得到去除背景的遮罩与图片，把拍摄图片添加绿幕（0,255,0）</li></ul></div><h3 id="🍦图片不同大小" tabindex="-1">🍦图片不同大小 <a class="header-anchor" href="#🍦图片不同大小" aria-label="Permalink to &quot;🍦图片不同大小&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">前提</p><ul><li>插件：【essentials】、【Custom-Scripts】、【LayerStyle】</li><li>节点工具：【数学表达式】、【拓展画布】</li><li>实现流程：通过随机函数并通过数学关系输入有限制的随机数将图像替换成等比例不同大小的图片</li></ul></div><h3 id="🥪图片背景" tabindex="-1">🥪图片背景 <a class="header-anchor" href="#🥪图片背景" aria-label="Permalink to &quot;🥪图片背景&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">前提</p><ul><li>插件：【BrushNet】、【LayerStyle】</li><li>节点工具：【BrushNet】、【BrushNet加载器】、【LaMa】</li><li>实现流程：通过模型处理可实现符合语义的背景替换</li></ul></div><ol><li>基本标志物随机数量</li><li>标志物纯色幕布抠图</li><li>参考图片反推</li><li>BrushNet背景生成</li><li>光影遮罩潜空间调整</li><li>IC-Light图片打光</li><li>雨幕蒙版添加</li><li>高清放大</li></ol><h3 id="基本标志物随机数量" tabindex="-1">基本标志物随机数量 <a class="header-anchor" href="#基本标志物随机数量" aria-label="Permalink to &quot;基本标志物随机数量&quot;">​</a></h3><p>for循环的初始值1接入空图像作为数据格式参考，数学表达式中randomchoice(1,4,4,4,4,4,9,9,9,9,16) 通过randomchoice函数选出随机的平方数进行拼图操作，保证图片融合之后长宽比例一致。 通过数学逻辑进行单张图片的缩放，首先获取图像尺寸，然后向四边进行扩图，同时保持长宽比例一致。</p><ol><li>图片长拓展像素</li><li>图片宽拓展像素</li></ol><p>通过逆分块进行图片合并，最终通过图像缩放生成720*544的图片。</p><div class="warning custom-block"><p class="custom-block-title">公式解读</p><p>单个图片 a:图片长度扩展的总长度 b:图片</p><p>a:图片长度扩展的总长度 b:图片宽度扩展的总宽度 c:图片向上扩展 d:图片向下扩展 e:图片向左扩展 f:图片向右扩展</p> 图片向上扩展=图片向上扩展； 图片向下扩展=图片宽度扩展的总宽度-图片向上扩展; 图片向上扩展= <p>通过数学运算节点进行尺寸计算，生成768 * 768的遮罩作为K采样器的潜空间图像。</p></div><div class="tip custom-block"><p class="custom-block-title">小纸条</p><p>对数学运算节点和逻辑节点针对性地串并联实现对图像的随机挑选与成比例缩放，然后单张处理图片进行平方数数量的合并，输出图像随机地出现不同数量标志物的绿幕图片作为后续处理输入。</p><ul><li>数学运算节点主要包括【数学表达式】、【整数】，通过数学关系对图像进行成比例的随机画布拓展，实现标志物生成在图片的不同位置，以及实现对有标志物的图片与无标志物的图片的随机挑选，实现图片中生成不同数量的标志物。</li><li>逻辑节点主要包括【For循环-起始】、【For循环-结束】、【比较】、【If else】，通过与【数学表达式】配合，实现对平方数图片的合并</li><li>图片处理节点主要包括【图像缩放】、【图像逆分块】等，实现最终图片以720*544分辨率输出</li></ul></div><h3 id="标志物纯色幕布抠图" tabindex="-1">标志物纯色幕布抠图 <a class="header-anchor" href="#标志物纯色幕布抠图" aria-label="Permalink to &quot;标志物纯色幕布抠图&quot;">​</a></h3><p>输入:【标志物随机数量】中输出的绿幕图片 输出:标志物为纯白色，绿幕为黑色的单色遮罩图片 通过判断纯绿色颜色进行遮罩的生成。 使用【图像颜色到遮罩】节点对【标志物随机生成】输出的图片进行绿幕识别，生成以标志物为白底，绿幕为黑底的遮罩图像。</p><h3 id="参考图片反推" tabindex="-1">参考图片反推 <a class="header-anchor" href="#参考图片反推" aria-label="Permalink to &quot;参考图片反推&quot;">​</a></h3><p>输入:【参考图片】 输出：【提示词】 加载Florence2-large模型对输入参考图像进行提示词反推，作为提示词输入。 通过Florence2模型加载进行参考图片的反推</p><h3 id="brushnet背景生成" tabindex="-1">BrushNet背景生成 <a class="header-anchor" href="#brushnet背景生成" aria-label="Permalink to &quot;BrushNet背景生成&quot;">​</a></h3><p>输入:【绿幕图片】、【遮罩图片】 输出:【添加背景后的图像】</p><p>通过调用基于sd1.5大模型训练的realisticVisionV51VAE_2大模型作为基础检测模型生成基本图像， 通过ip-adapter进行参考图像的风格转绘，基于CLIP视觉加载器 通过Brushnet对遮罩物品的背景生成 加载Checkpoint加载器，加载基于sd1.5大模型训练的realisticVisionV51VAE_2大模型作为基础检测模型，并使用IPAdapter模型进行风格转绘。之后，调用segmentation_mask_brushnet_ckpt模型，针对标志物在原本的绿幕上添加与提示词相对应的背景。</p><h3 id="光影遮罩潜空间调整" tabindex="-1">光影遮罩潜空间调整 <a class="header-anchor" href="#光影遮罩潜空间调整" aria-label="Permalink to &quot;光影遮罩潜空间调整&quot;">​</a></h3><p>输入:【标志物随机数量】中输出的绿幕图片 输出： 通过数学表达式进行随机渐变的遮罩。</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>randomchoice(x,y,z)等概率地选择其中一个数据</p></div><h3 id="ic-light图片打光" tabindex="-1">IC-Light图片打光 <a class="header-anchor" href="#ic-light图片打光" aria-label="Permalink to &quot;IC-Light图片打光&quot;">​</a></h3><p>输入:【添加背景的图片】 输出:【去除标志物的纯背景图像】 通过遮罩对Latent进行修整，从而实现对光照的分布调整</p><p>调用Lama模型进行去除标志物的纯背景图像提取，将提取的背景图像应用于IC-Light的背景潜空间输入，而【BrushNet背景生成】的图像作为IC-Light应用节点的前景潜空间输入，最后进行图片的重新打光。</p><h3 id="雨幕添加" tabindex="-1">雨幕添加 <a class="header-anchor" href="#雨幕添加" aria-label="Permalink to &quot;雨幕添加&quot;">​</a></h3><p>输入:提示词 输出:【雨幕图片】 通过一个普通的文生图生成雨幕 调用统一的realisticVisionV51VAE_2大模型使用基本文生图工作流进行雨幕图像生成。</p><h3 id="高清放大" tabindex="-1">高清放大 <a class="header-anchor" href="#高清放大" aria-label="Permalink to &quot;高清放大&quot;">​</a></h3><p>输入:【添加打光的图片】 输出:【1440*1080】 通过ControlNet进行图片细节保留再进行高清放大 使用ControlNet模型进行图片的高清放大，输出1024 * 1440的图片。然后，通过【图像混合模式】节点将雨幕与生成背景后的图像进行雨幕融合。最终，通过【图像线性】和【高斯模糊】节点生成彩色图像。在遮罩环节中，适当扩展遮罩以最大限度保持基本标志物的一致性。</p><h3 id="图像预览" tabindex="-1">图像预览 <a class="header-anchor" href="#图像预览" aria-label="Permalink to &quot;图像预览&quot;">​</a></h3><p>输入:【绿幕图片】、【线性图片】、【灰度图片】、【线性+模糊】、【线性+模糊+雨幕】 输出:图像对比效果</p><div class="tip custom-block"><p class="custom-block-title">小纸条</p><p>Florence-2是一种先进的视觉基础模型，采用基于提示的方法来处理广泛的视觉和视觉语言任务。 Florence-2可以解释简单的文本提示来执行诸如图像描述、物体检测和分割等任务。 它利用我们的FLD-5B数据集，该数据集包含1.26亿张图像的54亿个注释，以掌握多任务学习。 该模型的序列到序列架构使其能够在零样本和微调设置中都表现出色，证明是一个具有竞争力的视觉基础模型。</p></div><h3 id="类型保存" tabindex="-1">类型保存 <a class="header-anchor" href="#类型保存" aria-label="Permalink to &quot;类型保存&quot;">​</a></h3><h2 id="论文写作" tabindex="-1">论文写作 <a class="header-anchor" href="#论文写作" aria-label="Permalink to &quot;论文写作&quot;">​</a></h2><p>  ComfyUI界面采用节点式工作流，每个步骤作为一个节点，完成后的结果输入到下一个步骤，以此实现整个工作流程。本套工作流程主要分为8大板块：【标志物随机生成】、【光影遮罩空间调整】、【纯色幕布抠图遮罩】、【IC-Light】、【BrushNet背景生成】、【图片高清放大】、【参考图片反推】、【雨幕蒙版添加】。本文所引用的大模型是基于512 * 512图像训练的，初步思路是先完成768 * 768的小样，确认后再通过【图片高清放大】节点群进行高清尺寸放大。</p><h3 id="" tabindex="-1"><a class="header-anchor" href="#" aria-label="Permalink to &quot;&quot;">​</a></h3>',71)]))}const b=a(o,[["render",r]]);export{p as __pageData,b as default};
